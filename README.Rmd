---
output:
  md_document:
    variant: markdown_github
---


# Some spaCy & scispacy workflows

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("/home/jtimm/pCloudDrive/GitHub/packages/render_toc.R")
```



`r paste0('*Updated: ', Sys.Date(),'*')` 

> An attempt at organizing some `spaCy` workflows.  Some functions for disentangling `spaCy` output.   

---



```{r echo=FALSE}
render_toc(filename = "/home/jtimm/pCloudDrive/GitHub/git-projects/spacy-nlp/README.Rmd",
           toc_depth = 3,
           base_level = 1)
```


---


## Conda environment

```{bash eval=FALSE}
conda create -n scispacy python=3.9
source activate scispacy 
conda install transformers pandas numpy

cd /home/jtimm/anaconda3/envs/scispacy/bin/
pip install scispacy
# pip install pysbd
# pip install medspacy
pip install textacy
pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz
pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_ner_bc5cdr_md-0.4.0.tar.gz
```



## Reticulate

```{r message=FALSE, warning=FALSE}
## <R-console>
library(dplyr)
Sys.setenv(RETICULATE_PYTHON = "/home/jtimm/anaconda3/envs/scispacy/bin/python")
library(reticulate)
#reticulate::use_python("/home/jtimm/anaconda3/envs/m3demo/bin/python")
reticulate::use_condaenv(condaenv = "scispacy",
                         conda = "/home/jtimm/anaconda3/bin/conda")
```



## PubMed abstracts

```{r message=FALSE, warning=FALSE}
dd <- pubmedr::pmed_search_pubmed(search_term = 'alzheimers treatment', 
                                  fields = c('TIAB','MH'))

dd.df <- pubmedr::pmed_get_records2(pmids = unique(dd$pmid)[1:200], 
                                    with_annotations = F)[[1]] |>
  filter(!is.na(abstract))

df <- reticulate::r_to_py(dd.df)
```



```{python include=FALSE}
import pandas as pd
import os
import spacy
import scispacy
#nlp = spacy.load("en_core_sci_sm")
#nlp = spacy.load("en_core_web_sm")

nlp = spacy.load("en_ner_bc5cdr_md")

nlp.add_pipe("sentencizer", first=True)
nlp.add_pipe("merge_entities")

from scispacy.abbreviation import AbbreviationDetector
nlp.add_pipe("abbreviation_detector") # before="parser"

from scispacy.linking import EntityLinker
nlp.add_pipe("scispacy_linker", config={"resolve_abbreviations": True, "linker_name": "mesh"})

from scispacy.hyponym_detector import HyponymDetector
nlp.add_pipe("hyponym_detector", last=True, config={"extended": False})

linker = nlp.get_pipe("scispacy_linker")

texts = list(r.df['abstract'])
doc = list(nlp.pipe(texts))
```


## Libraries

```{python}
import sys
#print(sys.path)
sys.path.append('../home/jtimm/pCloudDrive/GitHub/git-projects/spacy-nlp')
import spacyHelp
```


```{python eval=FALSE}
import pandas as pd
import os
import spacy
import scispacy
#nlp = spacy.load("en_core_sci_sm")
#nlp = spacy.load("en_core_web_sm")
```



### Scispacy components

* `en_ner_bc5cdr_md`, A spaCy NER model trained on the BC5CDR corpus. For disease and chemical NER. Details for additional models available [here](https://allenai.github.io/scispacy/).

> Another option is to use the generic scispacy "mention detector", and then link to UMLS, eg. 

* An abbreviation detector.

* An entity linker -- here `umls`, but `mesh`, `rxnorm`, `go`, and `hpo` are also available knowledge bases that can be linked to.

* A hyponym detector.

```{python eval=FALSE}
nlp = spacy.load("en_ner_bc5cdr_md")
nlp.add_pipe("sentencizer", first=True)
nlp.add_pipe("merge_entities")

from scispacy.abbreviation import AbbreviationDetector
nlp.add_pipe("abbreviation_detector")

from scispacy.linking import EntityLinker
nlp.add_pipe(
  "scispacy_linker", 
  config={"resolve_abbreviations": True, 
  "linker_name": "mesh"})
  
linker = nlp.get_pipe("scispacy_linker")

from scispacy.hyponym_detector import HyponymDetector
nlp.add_pipe(
  "hyponym_detector", 
  last = True, 
  config={"extended": False})
```


```{python}
print(nlp.pipe_names)
```





## Spacy annotate

```{python eval=FALSE}
texts = list(r.df['abstract'])
doc = list(nlp.pipe(texts))
```



## Extraction functions

### Standard annotation

```{python}
sp_df = spacyHelp.spacy_get_df(doc)
```


```{r message=FALSE, warning=FALSE}
reticulate::py$sp_df |>
  slice(1:5) |> knitr::kable()
```




### Entities & linking

```{python}
sp_entities = spacyHelp.spacy_get_entities(
  doc, 
  link = True, 
  linker = linker)
```


```{r message=FALSE, warning=FALSE}
reticulate::py$sp_entities |>
  sample_n(15) |> knitr::kable()
```



### Abbreviations

```{python}
sp_abbrevs = spacyHelp.spacy_get_abbrevs(doc)
```


```{r message=FALSE, warning=FALSE}
reticulate::py$sp_abbrevs |>
  distinct(abrv, .keep_all = T) |>
  sample_n(15) |> knitr::kable()
```



### Noun phrases

```{python}
sp_noun_phrases = spacyHelp.spacy_get_nps(doc)
```


```{r message=FALSE, warning=FALSE}
reticulate::py$sp_noun_phrases |>
  sample_n(10) |> knitr::kable()
```


### Hyponyms

> Works better with nlp.add_pipe("merge_entities")

```{python}
sp_hearst = spacyHelp.spacy_get_hyponyms(doc)
```



```{r}
reticulate::py$sp_hearst |>
  select(doc_id, sbj, pred, obj) |>
  sample_n(15) |> knitr::kable()
```



### Negation

```{python eval=FALSE, include=FALSE}
# https://medium.com/@MansiKukreja/clinical-text-negation-handling-using-negspacy-and-scispacy-233ce69ab2ac
```


### Sentences

```{python}
sp_sentences = spacyHelp.spacy_get_sentences(doc)
```


```{r}
reticulate::py$sp_sentences |>
  sample_n(7) |> knitr::kable()
```





```{python eval=FALSE, include=FALSE}
## Medical transcript data

# Data from R package `clinspacy` via https://mtsamples.com/

# mts <- clinspacy::dataset_mtsamples()
# mts_df <- reticulate::r_to_py(mts)

### medspacy

# jupyter-notebook
import medspacy
# nlp = spacy.load("en_core_sci_sm")
nlp = medspacy.load("en_core_sci_sm", disable = {'medspacy_target_matcher', 'medspacy_pyrush'})
nlp.add_pipe("sentencizer", first = True)
sectionizer = nlp.add_pipe("medspacy_sectionizer")
print(nlp.pipe_names)


texts0 = list(r.mts_df['transcription'][1:100])
doc = list(nlp.pipe(texts0))


#  is_negated
#  is_uncertain
#  is_historical
#  is_family
#  is_hypothetical

def spacy_get_transcripts(docs):

    details_dict = {
      "doc_id": [], 
      "sent_id": [],
      "section_category": [],
      "entity": [], 
      "is_historical": [],
      "start": [], 
      "end": []
      }
    
    for ix, doc in enumerate(docs):
      for sent_i, sent in enumerate(doc.sents):
        
        for ent in sent.ents:
          details_dict["doc_id"].append(ix)
          details_dict["sent_id"].append(sent_i)
          details_dict["section_category"].append(ent._.section_category)
          details_dict["entity"].append(ent.text)
          details_dict["is_historical"].append(ent._.is_historical)
          details_dict["start"].append(ent.start)
          details_dict["end"].append(ent.end)
    
    dd =  pd.DataFrame.from_dict(details_dict)     
    return dd
  
sp_transcripts = spacy_get_transcripts(doc)
```




## References 

Eyre, A.B. Chapman, K.S. Peterson, J. Shi, P.R. Alba, M.M. Jones, T.L. Box, S.L. DuVall, O. V Patterson, Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python, AMIA Annu. Symp. Proc. 2021 (in Press. (n.d.).
http://arxiv.org/abs/2106.07799.

Kormilitzin, A., Vaci, N., Liu, Q., & Nevado-Holgado, A. (2021). Med7: A transferable clinical natural language processing model for electronic health records. Artificial Intelligence in Medicine, 118, 102086.

Neumann, M., King, D., Beltagy, I., & Ammar, W. (2019). ScispaCy: fast and robust models for biomedical natural language processing. arXiv preprint arXiv:1902.07669.





